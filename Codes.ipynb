{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Ben_codes_thusday.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgom-CUpMfb1"
      },
      "source": [
        "## Librairies importation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POQzDqWXKDJS"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import torch\n",
        "from torchvision import models\n",
        "import torch\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms, datasets, models\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "import os\n",
        "import numpy as np\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import cv2\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from pylab import *\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMglQ1jHkH44"
      },
      "source": [
        "## googlenet model downloading\n",
        "googlenet= models.googlenet(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYsee7kDkOBM"
      },
      "source": [
        "# googlenet model evaluation\n",
        "googlenet.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlmLlWFSkOHz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vkZTYftkOO9"
      },
      "source": [
        "from PIL import Image\n",
        "im = Image.open(\"/content/drive/MyDrive/BootCamp_Week_1/70bfca4555cca92e (2).jpg\")\n",
        "im \n",
        "# !wget https://github.com/benjaminbenteke/AMMI_BootCamp_Week_1/blob/28425f17b18823beb7431749bb499bdde355dfb2/image.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhNpvjJ6ZCM1"
      },
      "source": [
        "img= cv2.imread(\"/content/drive/MyDrive/BootCamp_Week_1/70bfca4555cca92e (2).jpg\")\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-pDul5wt-O1"
      },
      "source": [
        "def pre_processing(obs, cuda):\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape([1, 1, 3])\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape([1, 1, 3])\n",
        "    obs = obs / 255\n",
        "    obs = (obs - mean) / std\n",
        "    # obs = np.transpose(obs, (2, 0, 1))\n",
        "    # obs = np.expand_dims(obs, 0)\n",
        "    obs = np.array(obs)\n",
        "    if cuda:\n",
        "        torch_device = torch.device('cuda:0')\n",
        "    return obs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIZKoqmyrZKp"
      },
      "source": [
        "img= cv2.imread('/content/drive/MyDrive/BootCamp_Week_1/70bfca4555cca92e (2).jpg')\n",
        "img= pre_processing(img, False)\n",
        "img= np.transpose(img, (2,0,1))\n",
        "img= torch.tensor(img)\n",
        "img= np.expand_dims(img, 0)\n",
        "img= torch.tensor(img,dtype=torch.float)\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNhskFLV9Ukl"
      },
      "source": [
        "# Download ImageNet labels\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ecp9Keek_0d"
      },
      "source": [
        "with open('imagenet_classes.txt') as f:\n",
        "  categories = [line.strip() for line in f.readlines()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1wsajeumlFv"
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = googlenet(img)\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1jbijimk__s"
      },
      "source": [
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIoDzi8NlFx-"
      },
      "source": [
        "categories.index('fireboat') ## Target index for the image."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA21UWy5lNEf"
      },
      "source": [
        "# Integrated gradient methods\n",
        "* Idea behind Path;\n",
        "* Interpolated image;\n",
        "* Gradient;\n",
        "* Integrated Gradinet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmgod8O2wiTw"
      },
      "source": [
        "# Image importation\n",
        "\n",
        "img= cv2.imread('/content/drive/MyDrive/BootCamp_Week_1/70bfca4555cca92e (2).jpg')\n",
        "img= pre_processing(img, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bri-tdXAwilM"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I8D1hpmuTFG"
      },
      "source": [
        "# Interpolate images function\n",
        "\n",
        "def intepolate_img(input,baseline, alphas):\n",
        "  alphas_x = alphas[:, tf.newaxis, tf.newaxis, tf.newaxis]\n",
        "  alphas_x=tf.make_ndarray(tf.make_tensor_proto(alphas_x))\n",
        "  alphas_x=torch.tensor(alphas_x)\n",
        "\n",
        "  baseline_x= torch.unsqueeze(baseline, 0)\n",
        "  input_x= np.expand_dims(input, 0)\n",
        "  input_x = torch.tensor(input_x,dtype=float)\n",
        "  x_x_prime = input_x - baseline_x\n",
        "\n",
        "  images = baseline_x + alphas_x*x_x_prime\n",
        "\n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiNt6jGSuTYz"
      },
      "source": [
        "# baseline creation\n",
        "baseline = torch.zeros(size=(224,224,3))\n",
        "baseline.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKsjSDTC0K8T"
      },
      "source": [
        "figure(1)\n",
        "imshow(baseline, interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xallx5iwRuX"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu05elCQHHUU"
      },
      "source": [
        "m_steps=50\n",
        "alphas = tf.linspace(start=0.0, stop=1.0, num=m_steps+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pb2JOMBiI6zM"
      },
      "source": [
        "# Interpolation image computatation\n",
        "interpolated_images= intepolate_img(input=img, baseline=baseline,alphas=alphas) # This the path (all 51 images from baseline to the original image, include the baseline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFvSd9evbAXQ"
      },
      "source": [
        "interpolated_images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTY55FC2gJD-"
      },
      "source": [
        "<!-- <img src='/content/drive/MyDrive/BootCamp_Week_1/Integrated_gradient.png'> -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNiCbndTR0Ss"
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "i = 0\n",
        "for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
        "  i += 1\n",
        "  plt.subplot(1, len(alphas[0::10]), i)\n",
        "  plt.title(f'alpha: {alpha:.1f}')\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCPtI8gdv4mS"
      },
      "source": [
        "Image.open('/content/drive/MyDrive/BootCamp_Week_1/Integrated_gradient.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trsNGtjNvz96"
      },
      "source": [
        "# Explanations of the Paper. Brief\n",
        "* Interpolated images are image of the path, form baseline to original. They are obtained by increasing alpha (brightness), and for each interplated image, we make a prediction.\n",
        "* The value of alpha give us the number of interporlated images ([alpha,224,224,3]) because for each alpha we have an associated image.\n",
        "* The set of all interpolated images is called a Path. Path (all image from baseline to original image), in our case the path is a straight line. Or a Path is an array that contains all interpolated images.\n",
        "* We'll compute the gradient for interpolated_images and we aggregate them. This aggregated gradient is called, Integrated Gradient. # See the figure below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXqDQERBUJhe"
      },
      "source": [
        "# Prediction and Gradient \n",
        "def output_and_gradient_computation(inputs, model, target_label_idx, cuda=False):\n",
        "  \n",
        "    gradients = []\n",
        "\n",
        "    for input in inputs:\n",
        "\n",
        "      input= np.transpose(input, (2,0,1))\n",
        "      input= torch.tensor(input,dtype=torch.float)\n",
        "      input= input.unsqueeze(0)\n",
        "      input.requires_grad = True\n",
        "      output = model(input)\n",
        "      output = F.softmax(output, dim=1)\n",
        "\n",
        "\n",
        "      if target_label_idx is None:\n",
        "          target_label_idx = torch.argmax(output, 1).item()\n",
        "      index = np.ones((output.size()[0], 1)) * target_label_idx\n",
        "      index = torch.tensor(index, dtype=torch.int64)\n",
        "      if cuda:\n",
        "          index = index.cuda()\n",
        "      output = output.gather(1, index)\n",
        "\n",
        "      model.zero_grad()\n",
        "      output.backward()\n",
        "\n",
        "      gradient = input.grad.detach().cpu().numpy()[0]\n",
        "      gradients.append(gradient)\n",
        "    gradients = np.array(gradients)\n",
        "    return gradients, output, target_label_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNGC9OeRa1X6"
      },
      "source": [
        "grad, output, _= output_and_gradient_computation(interpolated_images, googlenet, 554, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG6dlGEjawuX"
      },
      "source": [
        "output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkVSDOoC1kt3"
      },
      "source": [
        "grad.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZgyIVR6yG57"
      },
      "source": [
        "## Integrated gradient implementation\n",
        "\n",
        "def integrated_gradients(inputs, model, target_label_idx, res, baseline, steps=50, cuda=False):\n",
        "  if baseline is None:\n",
        "        baseline = 0 * inputs \n",
        "  baseline= np.array(baseline)\n",
        "  avg_grads = np.average(res[:-1], axis=0)\n",
        "  avg_grads = np.transpose(avg_grads, (1, 2, 0))\n",
        "  delta_X = (pre_processing(inputs, cuda) - pre_processing(baseline, cuda))\n",
        "  integrated_grad = delta_X * avg_grads\n",
        "\n",
        "  return integrated_grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J42gLelUyHBz"
      },
      "source": [
        " ig= integrated_gradients(img, googlenet, 554, grad, baseline, 50, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJr_rybMysuD"
      },
      "source": [
        "ig.shape # must be the same shape as the original image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOqMZAeozN7q"
      },
      "source": [
        "## Visualizations\n",
        "def plot_img_attributions(baseline, image, target_class_idx, ig, m_steps=50, cmap=None, overlay_alpha=0.4):\n",
        "\n",
        "  attribution_mask = tf.reduce_sum(tf.math.abs(ig), axis=-1)\n",
        "\n",
        "  fig, axs = plt.subplots(nrows=2, ncols=2, squeeze=False, figsize=(8, 8))\n",
        "\n",
        "  axs[0, 0].set_title('Baseline image')\n",
        "  axs[0, 0].imshow(baseline)\n",
        "  axs[0, 0].axis('off')\n",
        "\n",
        "  axs[0, 1].set_title('Original image')\n",
        "  axs[0, 1].imshow(image)\n",
        "  axs[0, 1].axis('off')\n",
        "\n",
        "  axs[1, 0].set_title('Attribution mask')\n",
        "  axs[1, 0].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1, 0].axis('off')\n",
        "\n",
        "  axs[1, 1].set_title('Overlay')\n",
        "  axs[1, 1].imshow(attribution_mask, cmap=cmap)\n",
        "  axs[1, 1].imshow(image, alpha=overlay_alpha)\n",
        "  axs[1, 1].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlWNp5nR3Yu9"
      },
      "source": [
        "plot_img_attributions(baseline, im, 554,ig, m_steps=50, cmap=plt.cm.inferno, overlay_alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWROpyPu2p-c"
      },
      "source": [
        "grad.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW8TDH4O350o"
      },
      "source": [
        "# Average gradient at the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt1JWl4c22cz"
      },
      "source": [
        "avg_grads = np.average(grad[:-1], axis=0)\n",
        "avg_grads= np.transpose(avg_grads,(2,1,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfLwXzmP31fs"
      },
      "source": [
        "plot_img_attributions(baseline, im, 554,avg_grads, m_steps=50, cmap=plt.cm.inferno, overlay_alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi9_gZ6R33Kv"
      },
      "source": [
        "# End of the code. (these codes must be improved)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXH_GcEqabxL"
      },
      "source": [
        "from PIL import Image\n",
        "im= Image.open(\"/content/drive/MyDrive/BootCamp_Week_1/c0a9ce885a9c26bc.jpg\")\n",
        "im "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sIcmKJJ7kew"
      },
      "source": [
        "img= cv2.imread('/content/drive/MyDrive/BootCamp_Week_1/c0a9ce885a9c26bc.jpg')\n",
        "img= pre_processing(img, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfB9H1uC7zKj"
      },
      "source": [
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9gIdtiq8ZNd"
      },
      "source": [
        "img= np.transpose(img, (2,0,1))\n",
        "img= torch.tensor(img)\n",
        "img= np.expand_dims(img, 0)\n",
        "img= torch.tensor(img,dtype=torch.float)\n",
        "img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHsISkRs8Jdj"
      },
      "source": [
        "with torch.no_grad():\n",
        "    output = googlenet(img)\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61x2zpAn8TaY"
      },
      "source": [
        "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "for i in range(top5_prob.size(0)):\n",
        "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
        "\n",
        "im"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgSAqD1u8eTQ"
      },
      "source": [
        "categories.index('viaduct') ## Target index for the image."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWOv9mm8oGX"
      },
      "source": [
        "# Apply IG\n",
        "\n",
        "img= cv2.imread('/content/drive/MyDrive/BootCamp_Week_1/c0a9ce885a9c26bc.jpg')\n",
        "img= pre_processing(img, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVvaW8080kA"
      },
      "source": [
        "# Interpolation image computatation\n",
        "interpolated_images= intepolate_img(input=img, baseline=baseline,alphas=alphas) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAD1iRP287by"
      },
      "source": [
        "fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "i = 0\n",
        "for alpha, image in zip(alphas[0::10], interpolated_images[0::10]):\n",
        "  i += 1\n",
        "  plt.subplot(1, len(alphas[0::10]), i)\n",
        "  plt.title(f'alpha: {alpha:.1f}')\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKO-ev598-_8"
      },
      "source": [
        "grad, output, _= output_and_gradient_computation(interpolated_images, googlenet, 554, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmtl2iyf9EIc"
      },
      "source": [
        " ig= integrated_gradients(img, googlenet, 554, grad, baseline, 50, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r2iq_Oq9LIO"
      },
      "source": [
        "plot_img_attributions(baseline, im, 554,ig, m_steps=50, cmap=plt.cm.inferno, overlay_alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxo7MOw29LuP"
      },
      "source": [
        "avg_grads = np.average(grad[:-1], axis=0)\n",
        "avg_grads= np.transpose(avg_grads,(2,1,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da8awpgd9jgP"
      },
      "source": [
        "plot_img_attributions(baseline, im, 554,avg_grads, m_steps=50, cmap=plt.cm.inferno, overlay_alpha=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79jLcgRh9mIF"
      },
      "source": [
        "## "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}